{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpTqR0hXjqnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlXW6CQckLDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLl9YQXj3cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/TCS/Train.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axpIzOH-FwII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_df=df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wxbwlLQlBkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_df.dropna(inplace=True)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QRUMiSElVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_df.drop(columns=[\"Id\"],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnrlgTbxfqyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_df.reset_index(inplace=True)\n",
        "copy_df.drop(columns=[\"index\"], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rKRxcJM_aNXo",
        "colab": {}
      },
      "source": [
        "def cleaning(text):\n",
        "  list = []\n",
        "  codes = []\n",
        "  for i in range(copy_df.shape[0]):\n",
        "    clean = re.compile('<.*?>')\n",
        "    sentence = re.sub(clean, '',  copy_df[text][i] )\n",
        "    sentence = re.sub(r'C\\+\\+', 'CPP', sentence)\n",
        "    sentence = re.sub(r'C#', 'CSHARP', sentence)\n",
        "    sentence = re.sub(r'[^a-zA-Z0-9]+', ' ', sentence)\n",
        "    sentence = re.sub(r\"(?:^| )+[a-bd-qs-zA-BD-QS-Z](?=$| )+\", \"\", sentence)\n",
        "    sentence =\" \".join(sentence.split())\n",
        "    sentence = sentence.lower()\n",
        "    list.append(sentence)\n",
        "    if text==\"Body\":\n",
        "      code = str( re.findall(r\"<code>(.*?)</code>\", df[\"Body\"][i], flags=re.DOTALL) ) or \"\"\n",
        "      sentence = re.sub(r\"<code>(.*?)</code>\", \" \", df[\"Body\"][i], flags=re.MULTILINE|re.DOTALL)\n",
        "      codes.append(code)\n",
        "  copy_df[\"code\"]=codes\n",
        "  copy_df[text] = list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqjge5eeaORv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaning(\"Title\")\n",
        "cleaning(\"Body\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv-G9cKmefOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_df = pd.DataFrame()\n",
        "combined_df[\"Combined\"] = copy_df[\"Title\"] + \" \" + copy_df[\"Body\"] + \" \" + copy_df[\"Code\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDnXOc_Ma4Fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "033b4a4e-2e2d-47c1-abd1-9f890913363b"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8mPTrbb8Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(combined_df.shape[0]):\n",
        "  words = word_tokenize(copy_df.iloc[i,0])\n",
        "  t = \" \".join(str(stemmer.stem(word)) for word in words if word not in stop_words  )\n",
        "  tok_stop_stem_list.append(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XWv38zgdU0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,1), tokenizer=lambda x: x.split(), min_df=0.00009, max_features=25000)\n",
        "data1 = vectorizer.fit_transform(combined_df)\n",
        "ickle.dump(vectorizer.vocabulary_, open(\"final/vector1.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHvncoI8lkhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')\n",
        "data2 = vectorizer.fit_transform(copy_df['Tags'])\n",
        "pickle.dump(vectorizer.vocabulary_, open(\"final/vector2.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_xECKsGtpY4",
        "colab": {}
      },
      "source": [
        "data1_train, data1_test, data2_train, data2_test = train_test_split(data1, data2, test_size=0.05, random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bb2cr-fPtoNu",
        "colab": {}
      },
      "source": [
        "classfier_1 = OneVsRestClassifier(LogisticRegression(C=0.1, penalty='l2', verbose=1))\n",
        "classifier_1.fit(data1_train,data2_train)\n",
        "pickle.dump(classfier1, open(\"classifier/clf_1.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-l-Xmg4tn25",
        "colab": {}
      },
      "source": [
        "classifier_2 = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=1, penalty='l2',n_jobs=-1))\n",
        "classifier_2.fit(data1_train,data2_train)\n",
        "pickle.dump(clf_sgd_1, open(\"classifier/clf_2.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O80aJIa6tnbk",
        "colab": {}
      },
      "source": [
        "classifier_3 = OneVsRestClassifier(SVC())\n",
        "classifier_3.fit(X_train_1_1, y_train)\n",
        "pickle.dump(clf_svc, open(\"classifier/clf_3.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eQIIJBJ4tl4t",
        "colab": {}
      },
      "source": [
        "prediction = -1\n",
        "for i in range(1,4):\n",
        "  model = pickle.load(open(\"classifier/clf_\"+i+\".pickle\", \"rb\"))\n",
        "  max = model.predict(data1_test)\n",
        "  if prediction > max:\n",
        "    prediction = max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QGtLANNsz4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_vector = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"final/vector2.pickle\", \"rb\")))\n",
        "tags_vector._validate_vocabulary()\n",
        "ques_vector = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"final/vector1.pickle\", \"rb\")))\n",
        "ques_vector._validate_vocabulary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2En-KMurc2EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Results = pd.DataFrame({\"Questions\": ques_vector.inverse_transform(data1_test),\n",
        "                        \"Tags\": tags_vector.inverse_transform(prediction)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gu-iTTc2tj0c",
        "colab": {}
      },
      "source": [
        "Results.to_csv(\"Result/Results.csv\", index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}